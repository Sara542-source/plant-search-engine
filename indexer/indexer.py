import os
import json
import re
import unicodedata
from collections import defaultdict
from pypdf import PdfReader

# Importation de votre config mise √† jour
# Assurez-vous que config.py est bien dans le dossier 'indexer'
from config import get_stop_words, INDEX_OUTPUT_PATH, DATA_DIR_JSON, DATA_DIR_PDF


class Indexer:
    def __init__(self):
        # Index invers√© global
        self.index = defaultdict(dict)
        # M√©tadonn√©es pour l'affichage (Titre, Image, R√©sum√©)
        self.metadata = {}
        # Stop words charg√©s depuis config.py
        self.stop_words = get_stop_words()

        # Utilisation de VOS variables d√©finies dans config.py
        self.json_folder = DATA_DIR_JSON  # ../docs/Plantes
        self.pdf_folder = DATA_DIR_PDF  # ../docs/Concepts

    def retirer_accents(self, texte):
        """Nettoie les accents pour la normalisation (√©t√© -> ete)"""
        try:
            texte = unicodedata.normalize('NFD', texte)
            texte = "".join([c for c in texte if unicodedata.category(c) != 'Mn'])
            return texte
        except Exception:
            return texte

    def nettoyer_texte(self, texte, is_scientific=False):
        """
        Tokenisation et nettoyage adapt√© au contexte.
        is_scientific=True prot√®ge les noms latins.
        """
        if not texte:
            return []

        texte = texte.lower()

        # CAS 1 : Nom Scientifique (Latin)
        if is_scientific:
            # On garde les tirets pour le latin (ex: Mentha x piperita)
            texte = re.sub(r'[^a-z0-9\-]+', ' ', texte)
            return texte.strip().split()

        # CAS 2 : Texte G√©n√©ral (Fran√ßais / Darija)
        texte = self.retirer_accents(texte)

        # Gestion des mots compos√©s : on remplace tiret par espace
        # "anti-inflammatoire" -> "anti inflammatoire" (plus facile √† trouver)
        texte = texte.replace('-', ' ').replace('_', ' ')

        # On ne garde que les lettres et les chiffres
        texte = re.sub(r'[^a-z0-9]+', ' ', texte)

        mots = texte.split()

        # Filtrage (Stop words) et Stemming l√©ger
        mots_propres = []
        for mot in mots:
            if mot not in self.stop_words and len(mot) > 1:
                # Petite astuce : on enl√®ve le 's' final du pluriel si le mot est long
                if mot.endswith('s') and len(mot) > 3:
                    mots_propres.append(mot[:-1])
                else:
                    mots_propres.append(mot)

        return mots_propres

    def ajouter_au_dict(self, tokens, doc_id):
        """Ajoute les tokens nettoy√©s √† l'index invers√©"""
        for mot in tokens:
            if doc_id in self.index[mot]:
                self.index[mot][doc_id] += 1
            else:
                self.index[mot][doc_id] = 1

    def extraire_texte_recursif(self, structure):
        """
        Extrait le texte de n'importe quelle structure JSON imbriqu√©e
        (sections, children, listes, dicts...)
        """
        texte_accumule = ""

        if isinstance(structure, list):
            for element in structure:
                texte_accumule += self.extraire_texte_recursif(element)

        elif isinstance(structure, dict):
            # On prend le titre et le contenu de la section actuelle
            texte_accumule += structure.get('title', '') + " "
            texte_accumule += structure.get('content', '') + " "

            # On descend r√©cursivement dans les sous-sections
            if 'sections' in structure:
                texte_accumule += self.extraire_texte_recursif(structure['sections'])
            if 'children' in structure:
                texte_accumule += self.extraire_texte_recursif(structure['children'])

        return texte_accumule

    def indexer_json(self):
        """Traitement des plantes (JSON)"""
        print(f"\nüìÇ Indexation JSON depuis : {self.json_folder}")

        if not os.path.exists(self.json_folder):
            print(f"‚ùå Erreur : Dossier introuvable {self.json_folder}")
            return

        count = 0
        for filename in os.listdir(self.json_folder):
            if filename.endswith(".json"):
                filepath = os.path.join(self.json_folder, filename)
                doc_id = filename

                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        infos = data.get('infos_generales', {})

                        # --- 1. M√âTADONN√âES (Pour l'affichage) ---
                        self.metadata[doc_id] = {
                            "titre": infos.get('nom_commun', 'Plante'),
                            "sous_titre": infos.get('nom_scientifique', ''),
                            # On prend la premi√®re image ou None
                            "image": data.get('galerie_images', [None])[0],
                            # On prend un bout du r√©sum√© pour l'aper√ßu
                            "resume": data.get('source_data', {}).get('resume', '')[:250] + "...",
                            "type": "plante"
                        }

                        # --- 2. CONSTRUCTION DU TEXTE √Ä INDEXER ---
                        contenu = f"{infos.get('nom_commun', '')} {infos.get('nom_scientifique', '')} "
                        contenu += " ".join(infos.get('noms_darija', [])) + " "
                        contenu += " ".join(infos.get('noms_alternatifs', [])) + " "

                        # Attributs sp√©cifiques (dynamiques)
                        attrs = data.get('attributs_specifiques', {})
                        for k, v in attrs.items(): contenu += f"{k} {v} "

                        # Caract√©ristiques
                        caracs = data.get('caracteristiques', {})
                        contenu += f"{caracs.get('arrosage', '')} {caracs.get('type_sol', '')} "

                        # Utilisations
                        usages = data.get('utilisations', {})
                        for cat, liste in usages.items(): contenu += " ".join(liste) + " "

                        # Texte complet r√©cursif
                        source = data.get('source_data', {})
                        contenu += source.get('resume', '') + " "
                        full_text = source.get('texte_complet', {})
                        contenu += full_text.get('introduction', '') + " "
                        contenu += self.extraire_texte_recursif(full_text.get('sections', []))

                        # --- 3. INDEXATION ---
                        # Nom Scientifique (Mode prot√©g√©)
                        tokens_science = self.nettoyer_texte(infos.get('nom_scientifique', ''), is_scientific=True)
                        self.ajouter_au_dict(tokens_science, doc_id)

                        # Reste du texte (Mode normal)
                        tokens_texte = self.nettoyer_texte(contenu, is_scientific=False)
                        self.ajouter_au_dict(tokens_texte, doc_id)

                        count += 1

                except Exception as e:
                    print(f"‚ö†Ô∏è Erreur JSON {filename}: {e}")
        print(f"‚úÖ {count} plantes index√©es.")

    def indexer_pdf(self):
        """Traitement des concepts (PDF Texte Simple)"""
        print(f"\nüìÇ Indexation PDF depuis : {self.pdf_folder}")

        if not os.path.exists(self.pdf_folder):
            print(f"‚ùå Erreur : Dossier introuvable {self.pdf_folder}")
            return

        count = 0
        for filename in os.listdir(self.pdf_folder):
            if filename.endswith(".pdf"):
                filepath = os.path.join(self.pdf_folder, filename)
                doc_id = filename

                try:
                    reader = PdfReader(filepath)
                    texte_complet = ""
                    # On aspire tout le texte
                    for page in reader.pages:
                        extracted = page.extract_text()
                        if extracted:
                            texte_complet += extracted + " "

                    # --- 1. M√âTADONN√âES PDF ---
                    # Titre propre bas√© sur le nom du fichier (Arrosage_plante.pdf -> Arrosage plante)
                    titre_propre = filename.replace('.pdf', '').replace('_', ' ').capitalize()

                    # G√©n√©ration d'un r√©sum√© automatique (200 premiers caract√®res de la definition ou lintroduction)
                    # 1. On d√©finit les mots-cl√©s qui annoncent le d√©but du contenu int√©ressant
                    # On met "d√©finition" en premier car c'est le plus probable
                    mots_cles_debut = ["d√©finition", "definition", "introduction", "g√©n√©ralit√©s"]

                    resume_auto = ""
                    texte_lower = texte_complet.lower()

                    # 2. On cherche la position du premier mot-cl√© trouv√©
                    index_trouve = -1
                    for mot in mots_cles_debut:
                        # On cherche le mot cl√© (ex: "d√©finition")
                        index = texte_lower.find(mot)
                        if index != -1:
                            # Si trouv√©, on se place juste apr√®s le mot (+ sa longueur)
                            index_trouve = index + len(mot)
                            break

                    # 3. Extraction du r√©sum√©
                    if index_trouve != -1:
                        # Cas A : On a trouv√© "D√©finition"
                        # On prend les 300 caract√®res qui suivent
                        extrait = texte_complet[index_trouve: index_trouve + 300]

                        # Nettoyage : On enl√®ve les deux points (:), les tirets ou les sauts de ligne au d√©but
                        # Ex: "D√©finition : La botanique..." -> devient "La botanique..."
                        extrait = extrait.lstrip(" :.-\n\r\t")

                        resume_auto = extrait.replace('\n', ' ') + "..."
                    else:
                        # Cas B : Pas de mot "D√©finition", on prend le d√©but du PDF (Fallback)
                        resume_auto = texte_complet[:250].replace('\n', ' ') + "..."
                    # S√©curit√© si le texte est vide
                    if not resume_auto.strip():
                            resume_auto = "Aper√ßu non disponible."
                    self.metadata[doc_id] = {
                        "titre": titre_propre,
                        "sous_titre": "Fiche Concept",
                        "image": None,  # EXPLICITEMENT None car pas de photo
                        "resume": resume_auto,
                        "type": "concept"
                    }

                    # --- 2. INDEXATION ---
                    tokens = self.nettoyer_texte(texte_complet, is_scientific=False)
                    self.ajouter_au_dict(tokens, doc_id)

                    count += 1
                    print(f"  - {filename} trait√©")

                except Exception as e:
                    print(f"‚ö†Ô∏è Erreur PDF {filename}: {e}")

        print(f"‚úÖ {count} concepts PDF index√©s.")

    def sauvegarder(self):
        """Sauvegarde finale"""
        print(f"\nüíæ Sauvegarde vers {INDEX_OUTPUT_PATH}...")
        output_data = {"metadata": self.metadata, "index": self.index}

        try:
            with open(INDEX_OUTPUT_PATH, 'w', encoding='utf-8') as f:
                # indent=None r√©duit la taille du fichier (pas d'espaces inutiles)
                json.dump(output_data, f, ensure_ascii=False)
            print(f"üéâ SUCC√àS ! Index g√©n√©r√©.")
            print(f"üìä Stats : {len(self.index)} mots uniques index√©s.")
        except Exception as e:
            print(f"‚ùå Erreur sauvegarde : {e}")


if __name__ == "__main__":
    moteur = Indexer()
    moteur.indexer_json()
    moteur.indexer_pdf()
    moteur.sauvegarder()